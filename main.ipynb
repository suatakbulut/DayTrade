{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> <center> Predicting Day Trade Return by Deep Learning </center> </h1>\n",
    "\n",
    "The aim of this project is predicting the possible outcome of a day trade by training a deep learning model on the image data of 22 day long candle stick charts with some financial indicators drawn on them, bollinger bands and 20 day moving average for now. \n",
    "\n",
    "- **Data Scraping**: \n",
    "\n",
    "\tFor 242 stocks listed in S&P500 index, the historical price data for the last ten years are scraped. \n",
    "\n",
    "- **Creating .png images***:\n",
    "\n",
    "\tFor every 22 day long intervals, I draw the candlestick chart of the data along with some financial indicators (bollinger bands for now) on it. Create images that look like as follows:\n",
    "    <img src=\"sample_image.png\" style=\"height:256px\" >\n",
    "\tFor each image file, I created day_trade_precentage feature - which is calculated as the percentage return of buying the stock at the Close price of the 22nd day (the last day included in the candle stick chart) and selling it at the next day's Close price. Then I discretized the percentage returns into N (so far tried 3 and 14) many categories and label the images as one of these categories. \n",
    "\tSave the image files in the directory images/label, where label is its category. \n",
    "\n",
    "- **Preparing Data Directory for flow_from_directory**: \n",
    "\n",
    "\tIn order to be able to use flow_from_directory method of Keras, split the data into 3 directories under images_separated directory, called train_data, validation_data, test_data. The structure of the directory is as follows:\n",
    "\n",
    "\t```pyton \n",
    "    images_separated/\n",
    "\t\ttrain_data/\n",
    "\t\t\tlabel_1/\n",
    "\t\t\t\ttrain1_image_1.png\n",
    "\t\t\t\ttrain1_image_2.png\n",
    "\t\t\t\t...\n",
    "\t\t\tlabel_2/\n",
    "\t\t\t\ttrain2_image_1.png\n",
    "\t\t\t\ttrain2_image_2.png\n",
    "\t\t\t\t...\n",
    "\t\t\t...\n",
    "\t\tvalidation_data/\n",
    "\t\t\tlabel_1/\n",
    "\t\t\t\tvalidation1_image_1.png\n",
    "\t\t\t\tvalidation1_image_2.png\n",
    "\t\t\t\t...\n",
    "\t\t\tlabel_2/\n",
    "\t\t\t\tvalidation2_image_1.png\n",
    "\t\t\t\tvalidation2_image_2.png\n",
    "\t\t\t\t...\n",
    "\t\t\t...\n",
    "\t\ttest_data/\n",
    "\t\t\tlabel_1/\n",
    "\t\t\t\ttest1_image_1.png\n",
    "\t\t\t\ttest1_image_2.png\n",
    "\t\t\t\t...\n",
    "\t\t\tlabel_2/\n",
    "\t\t\t\ttest2_image_1.png\n",
    "\t\t\t\ttest2_image_2.png\n",
    "\t\t\t\t...\n",
    "\t\t\t...\n",
    "    ```\n",
    "\n",
    "- **Train CNN model**: \n",
    "\n",
    "\tThe architecture of the CNN model is as follows:\n",
    "\n",
    "\n",
    "- **Results**: \n",
    "\n",
    "Below is the table showing the the accuracy as the number of categories representing the discretized percentage returns changes\n",
    "\n",
    "|  num_cat |   14   |    5   |\n",
    "|----------|--------|--------|\n",
    "| accuracy |  0.18  | 0.3488 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option to skip some processes \n",
    "\n",
    "Steps before modelling takes so long and not needed to be kept repeated. So, I create an option to skip them individually. However, makes ure that if you decide not skip data scraping step, you must nor skip any other steps either. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do you want to skip data scraping? (y / n): y\n",
      "Do you want to skip creating candle stick charts? (y / n): y\n",
      "Do you want to skip splitting the image directory into train/validation/test sub-directories? (y / n): n\n"
     ]
    }
   ],
   "source": [
    "is_skip_scrape = input(\"Do you want to skip data scraping? (y / n): \")\n",
    "is_skip_image_create    = input(\"Do you want to skip creating candle stick charts? (y / n): \")\n",
    "is_skip_directory_split = input(\"Do you want to skip splitting the image directory into train/validation/test sub-directories? (y / n): \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the required packages\n",
    "import plotly.graph_objects as go\n",
    "import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_stocks = [\n",
    "\"MSFT\", \"AAPL\", \"AMZN\", \"GOOG\", \"GOOGL\", \"FB\", \"BRK.B\", \"V\", \"WMT\", \"JPM\", \"PG\", \n",
    "\"MA\", \"UNH\", \"INTC\", \"VZ\", \"T\", \"HD\", \"BAC\", \"MRK\", \"DIS\", \"PFE\", \"PEP\", \"CSCO\", \n",
    "\"CMCSA\", \"ORCL\", \"NFLX\", \"XOM\", \"NVDA\", \"ADBE\", \"ABT\", \"CRM\", \"NKE\", \"CVX\", \"LLY\", \"COST\", \n",
    "\"WFC\", \"MCD\", \"MDT\", \"BMY\", \"AMGN\", \"NEE\", \"PYPL\", \"TMO\", \"PM\", \"ABBV\", \"ACN\", \"CHTR\", \n",
    "\"LMT\", \"DHR\", \"UNP\", \"IBM\", \"TXN\", \"HON\", \"AVGO\", \"GILD\", \"C\", \"BA\", \"LIN\", \"UTX\", \n",
    "\"UPS\", \"SBUX\", \"MMM\", \"CVS\", \"QCOM\", \"FIS\", \"AXP\", \"TMUS\", \"MDLZ\", \"MO\", \"BLK\", \"LOW\", \"GE\", \n",
    "\"FISV\", \"CME\", \"D\", \"CI\", \"INTU\", \"SYK\", \"SO\", \"BDX\", \"PLD\", \"CAT\", \"EL\", \"SPGI\", \n",
    "\"ISRG\", \"CCI\", \"AGN\", \"TJX\", \"ADP\", \"VRTX\", \"ANTM\", \"CL\", \"GS\", \"AMD\", \"USB\", \"ZTS\", \"NOC\", \n",
    "\"MS\", \"NOW\", \"BIIB\", \"BKNG\", \"EQIX\", \"REGN\", \"CB\", \"MU\", \"TGT\", \"ITW\", \"ECL\", \"TFC\", \n",
    "\"ATVI\", \"CSX\", \"GPN\", \"SCHW\", \"MMC\", \"PGR\", \"PNC\", \"BSX\", \"KMB\", \"APD\", \"DE\", \"SHW\", \"AMAT\", \n",
    "\"AEP\", \"MCO\", \"EW\", \"WM\", \"BAX\", \"LHX\", \"NSC\", \"ILMN\", \"RTN\", \"HUM\", \"WBA\", \"SPG\",  \n",
    "\"GD\", \"NEM\", \"DG\", \"SRE\", \"LRCX\", \"EXC\", \"DLR\", \"PSA\", \"ADI\", \"ROP\", \"CNC\", \"LVS\", \"COP\", \n",
    "\"FDX\", \"GIS\", \"KMI\", \"ADSK\", \"XEL\", \"ETN\", \"GM\", \"MNST\", \"ROST\", \"KHC\", \"HCA\", \"SBAC\", \"BK\", \n",
    "\"MET\", \"WEC\", \"ALL\", \"EMR\", \"STZ\", \"EA\", \"HSY\", \"ES\", \"ED\", \"SYY\", \"CTSH\", \"AFL\", \n",
    "\"MAR\", \"TRV\", \"COF\", \"DD\", \"HRL\", \"HPQ\", \"RSG\", \"EBAY\", \"INFO\", \"MSCI\", \"EQR\", \"ORLY\", \"MSI\", \n",
    "\"TROW\", \"KR\", \"PSX\", \"VFC\", \"AVB\", \"PEG\", \"VRSK\", \"KLAC\", \"AIG\", \"MCK\", \"APH\", \"A\", \"AWK\", \n",
    "\"CLX\", \"PAYX\", \"WLTW\", \"DOW\", \"PRU\", \"TEL\", \"BLL\", \"EOG\", \"FE\", \"IQV\", \"YUM\", \"PCAR\", \"F\", \n",
    "\"RMD\", \"WELL\", \"K\", \"VRSN\", \"EIX\", \"PPG\", \"AZO\", \"JCI\", \"TWTR\", \"CMI\", \"IDXX\", \"TT\", \"ZBH\", \n",
    "\"O\", \"PPL\", \"ETR\", \"HLT\", \"ANSS\", \"SLB\", \"DAL\", \"CTAS\", \"LUV\", \"DTE\", \"XLNX\", \"SNPS\", \n",
    "\"ADM\", \"ALXN\", \"VLO\", \"AEE\", \"CERN\", \"DLTR\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the previously scraped data located at /data_folder/.\n"
     ]
    }
   ],
   "source": [
    "# Import the data scraping tool from functions folder\n",
    "from functions.Scrape_Historical_Data import scrape_historical_data\n",
    "\n",
    "if is_skip_scrape != 'y':\n",
    "    for stock_code in list_stocks: \n",
    "        scrape_historical_data(stock_code)\n",
    "    print('\\nData scraping is complete.')\n",
    "else:\n",
    "    print('Using the previously scraped data located at /data_folder/.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Data and Creating Image Files \n",
    "\n",
    "Now that we have our historical price data stored in .csv files, we can clean data, create labels based on the possible outcome of a day trade, and draw bollinger bands on top of their 22-day long candlesticks. As a result, we will have around 550,000 images that look like as follows: \n",
    "<img src=\"sample_image.png\" style=\"height:256px\" >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the previously prepared .png files located at /images/.\n"
     ]
    }
   ],
   "source": [
    "if is_skip_image_create != 'y':\n",
    "    # Import the necessary tools to clean the data set and create the \n",
    "    # candlestick charts with the bollinger bands from functions folder\n",
    "    from functions.DataFrame_Preprocessors import cleaner, calculate_return, categorizer \n",
    "    from functions.Bollinger_Bands import bollinger_bands \n",
    "    from functions.Image_Creator import image_creator \n",
    "\n",
    "    time_interval = 22\n",
    "    categories = (-1, 0, 1)\n",
    "\n",
    "    for sub_dir in categories:\n",
    "        images_dir = 'images/{}'.format(sub_dir)\n",
    "        if not os.path.exists(images_dir):\n",
    "            os.makedirs(images_dir)\n",
    "\n",
    "    for stock_name in os.listdir('historical_price_data'):    \n",
    "        data_path = 'historical_price_data/' + stock_name \n",
    "\n",
    "        if os.stat(data_path).st_size <= 5:\n",
    "            continue  \n",
    "\n",
    "        stock_price = pd.read_csv(data_path)\n",
    "\n",
    "        if len(stock_price) < 200 :\n",
    "            continue \n",
    "\n",
    "        stock_price = cleaner(stock_price)\n",
    "        stock_price = bollinger_bands(stock_price)\n",
    "        stock_price = calculate_return(stock_price)\n",
    "        stock_price = categorizer(stock_price)\n",
    "\n",
    "        for start in range(len(stock_price) - time_interval):\n",
    "            end = start + time_interval\n",
    "            sub_stock_price = stock_price[start: end] \n",
    "            file_name = '{}_{}'.format(stock_name[:-4], start)\n",
    "\n",
    "            image_creator(df = sub_stock_price, file_name = file_name)\n",
    "else:\n",
    "    print('Using the previously prepared .png files located at /images/.')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting Data into Train / Validation / Test Directories \n",
    "\n",
    "Using the *train_test_directory_split* tool in functions folder, we split our data into three subsets, namely train (60%), validation (20%), and test (20%). Once *train_test_directory_split()* does its job, we will have a folder, images_separated, that in in the following format so that it can be fed into *ImageDataGenerator* method of Keras API. \n",
    "\n",
    "```pyton \n",
    "    images_separated/\n",
    "\t\ttrain_data/\n",
    "\t\t\tlabel_1/\n",
    "\t\t\t\ttrain1_image_1.png\n",
    "                train1_image_2.png\n",
    "\t\t\t\t...\n",
    "\t\t\tlabel_2/\n",
    "\t\t\t\ttrain2_image_1.png\n",
    "\t\t\t\t...\n",
    "\t\t\t...\n",
    "\t\tvalidation_data/\n",
    "\t\t\tlabel_1/\n",
    "\t\t\t\tvalidation1_image_1.png\n",
    "\t\t\t\t...\n",
    "\t\t\tlabel_2/\n",
    "\t\t\t\tvalidation2_image_1.png\n",
    "\t\t\t\t...\n",
    "\t\t\t...\n",
    "\t\ttest_data/\n",
    "\t\t\tlabel_1/\n",
    "\t\t\t\ttest1_image_1.png\n",
    "\t\t\t\t...\n",
    "\t\t\tlabel_2/\n",
    "\t\t\t\ttest2_image_1.png\n",
    "\t\t\t\t...\n",
    "\t\t\t...\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=====================================\n",
      "Total images in class -1 is 164605\n",
      "\t98763 copied to ../training/-1\n",
      "\t32921 copied to ../validation/-1\n",
      "\t32921 copied to ../testing/-1\n",
      "\n",
      "=====================================\n",
      "Total images in class 0 is 189794\n",
      "\t113876 copied to ../training/0\n",
      "\t37959 copied to ../validation/0\n",
      "\t37959 copied to ../testing/0\n",
      "\n",
      "=====================================\n",
      "Total images in class 1 is 189666\n",
      "\t113799 copied to ../training/1\n",
      "\t37933 copied to ../validation/1\n",
      "\t37934 copied to ../testing/1\n"
     ]
    }
   ],
   "source": [
    "if is_skip_directory_split != 'y':\n",
    "    # Import the directory splitting tool from functions folder\n",
    "    from functions.Train_Test_Directory_Split import train_test_directory_split\n",
    "    \n",
    "    categories = (-1, 0, 1)\n",
    "    # Prepare the data directory to flow_from_direcoty method \n",
    "    train_test_directory_split(classes=categories)\n",
    "else:\n",
    "    print('Using the previously splitted data located at /images_separated/.') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning Model \n",
    "\n",
    "Now I will train a CNN model with two convolution layers with 3x3 kernel size and relu activation functions. Then I add two dense layers with 22 neurons. The main reason I chose 22 is that I am analyzing 22 day intervals. Once the model is compiled, following code will also print the summary of the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 256, 256, 256)     25856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 85, 85, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 85, 85, 128)       819328    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 28, 28, 64)        204864    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 9, 9, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 5184)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                331840    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 1,384,067\n",
      "Trainable params: 1,384,067\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Conv2D, AveragePooling2D, Dense, Flatten, MaxPooling2D\n",
    "from keras.models import Sequential \n",
    "\n",
    "cnn = Sequential() \n",
    "\n",
    "cnn.add(Conv2D(256, kernel_size=(5,5), input_shape=(256, 256, 4), padding='same', activation='relu')) \n",
    "cnn.add(MaxPooling2D(pool_size=(3,3))) \n",
    "\n",
    "cnn.add(Conv2D(128, kernel_size=(5,5), padding='same', activation='relu')) \n",
    "cnn.add(MaxPooling2D(pool_size=(3,3))) \n",
    "\n",
    "cnn.add(Conv2D(64,  kernel_size=(5,5), padding='same', activation='relu')) \n",
    "cnn.add(MaxPooling2D(pool_size=(3,3))) \n",
    "\n",
    "cnn.add(Flatten()) \n",
    "cnn.add(Dense(64, activation = 'relu')) \n",
    "cnn.add(Dense(32, activation = 'relu')) \n",
    "cnn.add(Dense(3, activation = 'softmax')) \n",
    "\n",
    "cnn.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy']) \n",
    "print(cnn.summary()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the *flow_from_directory* method of Keras API, I feed in my train and validation data into my cnn model as batches of size 10. The original size of my images is 256x256, here in this example I shirnk them to half. Moreover, I handle the normalization during the same process by rescaling my data 1/255. Once I create my train and validation data generators, I feed them into my cnn model to train it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 326438 images belonging to 3 classes.\n",
      "Found 108813 images belonging to 3 classes.\n",
      "Epoch 1/6\n",
      "65288/65288 [==============================] - 15153s 232ms/step - loss: 1.0966 - accuracy: 0.3494 - val_loss: 1.0975 - val_accuracy: 0.3488\n",
      "Epoch 2/6\n",
      "65288/65288 [==============================] - 23331s 357ms/step - loss: 1.0966 - accuracy: 0.3496 - val_loss: 1.0400 - val_accuracy: 0.3488\n",
      "Epoch 3/6\n",
      "65288/65288 [==============================] - 12184s 187ms/step - loss: 1.0966 - accuracy: 0.3484 - val_loss: 1.1139 - val_accuracy: 0.3486\n",
      "Epoch 4/6\n",
      "65288/65288 [==============================] - 12179s 187ms/step - loss: 1.0966 - accuracy: 0.3497 - val_loss: 1.0600 - val_accuracy: 0.3488\n",
      "Epoch 5/6\n",
      "65288/65288 [==============================] - 23872s 366ms/step - loss: 1.0966 - accuracy: 0.3489 - val_loss: 1.0640 - val_accuracy: 0.3488\n",
      "Epoch 6/6\n",
      "65288/65288 [==============================] - 37939s 581ms/step - loss: 1.0966 - accuracy: 0.3488 - val_loss: 1.1976 - val_accuracy: 0.3488\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "# Create train data generator\n",
    "train_datagen = ImageDataGenerator(rescale=1./255) \n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        'images_separated/train_data',\n",
    "        color_mode = 'rgba', \n",
    "        shuffle = True, \n",
    "        batch_size=5) \n",
    "\n",
    "# Create validation data generator\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)  \n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "        'images_separated/validation_data',\n",
    "        color_mode = 'rgba', \n",
    "        shuffle = True, \n",
    "        batch_size=5) \n",
    "\n",
    "# Fit the model\n",
    "history  = cnn.fit_generator(\n",
    "        train_generator,\n",
    "        epochs= 6,\n",
    "        validation_data=validation_generator\n",
    "        ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that model is trained, we can test it on our test data, generated by following test data generaotr. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 108814 images belonging to 3 classes.\n",
      "Test Accuracy is 34.88 %\n"
     ]
    }
   ],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        'images_separated/test_data',\n",
    "        color_mode = 'rgba', \n",
    "        shuffle = True, \n",
    "        batch_size = 5)\n",
    "\n",
    "# Calculate the accuracy of the model's predictions on the test data\n",
    "test_loss, test_acc = cnn.evaluate_generator(test_generator, verbose=2)\n",
    "print(\"Test Accuracy is {} %\".format(round(100*test_acc,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like we have pretty low accuracy. Observe that this accuracy could have been achieved by assigning all the test data into the same category since the size of our categories are almost 1/3. How about the precision and the recall of our model? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[    0 32921     0]\n",
      " [    0 37959     0]\n",
      " [    0 37934     0]]\n"
     ]
    }
   ],
   "source": [
    "labels_true = test_generator.classes\n",
    "labels_pred_probs = cnn.predict_generator(test_generator) \n",
    "labels_pred = np.argmax(labels_pred_probs, axis=1)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(labels_true, labels_pred)\n",
    "print(cm) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results \n",
    "\n",
    "Here we have tried to classify the 22 day candlestick chart of a stock with its bollinger bands into three categories, namely as follows: \n",
    "    \n",
    "    - category  1: percentage return > 0.5% \n",
    "    - category  0: percentage return between -0.5% and +0.5% \n",
    "    - category -1: percentage return < -0.5% \n",
    "\n",
    "The resulting accuracy is 34.88%. What we see in the confusion matrix is that our model is a really bad one since it assigns all the test images into the same class. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

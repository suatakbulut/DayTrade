{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> <center> Predicting Day Trade Return by Deep Learning </center> </h1>\n",
    "\n",
    "The aim of this project: Predicting the possible outcome of a day trade by training a deep learning model on the image data of historic candle stick charts with some financial indicators drawn on them \n",
    "\n",
    "- **Data Scraping**: \n",
    "\n",
    "\tFor 100 stocks listed in S&P500 index, scraped the historical price data for the last five years. \n",
    "\n",
    "\n",
    "- **Creating .png images***:\n",
    "\n",
    "\tFor ever 22 day long interval, draw the candlestick chart of the data along with some financial indicators (bollinger bands for now) on it\n",
    "\tFor each image file, created day_trade_precentage feature - calculated as the percentage return of buying the stock at the Close price of the 22nd day (the last day included in the candle stick chart) and selling it at the next day's Close price\n",
    "\tDiscretized the percentage return into N many categories. \n",
    "\t\tHow are the categories created? \n",
    "\tSave the image files in the directory images/label, where label is its category\n",
    "\n",
    "\n",
    "- **Preparing Data Directory for flow_from_directory**: \n",
    "\n",
    "\tIn order to be able to use flow_from_directory method of Keras, split the data into 3 directories under images_separated directory, called train_data, validation_data, test_data. The structure of the directory is as follows:\n",
    "\n",
    "\t```pyton \n",
    "    images_separated/\n",
    "\t\ttrain_data/\n",
    "\t\t\tlabel_1/\n",
    "\t\t\t\ttrain1_image_1.png\n",
    "\t\t\t\ttrain1_image_2.png\n",
    "\t\t\t\t...\n",
    "\t\t\tlabel_2/\n",
    "\t\t\t\ttrain2_image_1.png\n",
    "\t\t\t\ttrain2_image_2.png\n",
    "\t\t\t\t...\n",
    "\t\t\t...\n",
    "\t\tvalidation_data/\n",
    "\t\t\tlabel_1/\n",
    "\t\t\t\tvalidation1_image_1.png\n",
    "\t\t\t\tvalidation1_image_2.png\n",
    "\t\t\t\t...\n",
    "\t\t\tlabel_2/\n",
    "\t\t\t\tvalidation2_image_1.png\n",
    "\t\t\t\tvalidation2_image_2.png\n",
    "\t\t\t\t...\n",
    "\t\t\t...\n",
    "\t\ttest_data/\n",
    "\t\t\tlabel_1/\n",
    "\t\t\t\ttest1_image_1.png\n",
    "\t\t\t\ttest1_image_2.png\n",
    "\t\t\t\t...\n",
    "\t\t\tlabel_2/\n",
    "\t\t\t\ttest2_image_1.png\n",
    "\t\t\t\ttest2_image_2.png\n",
    "\t\t\t\t...\n",
    "\t\t\t...\n",
    "    ```\n",
    "\n",
    "- **Train CNN model**: \n",
    "\n",
    "\tThe architecture of the CNN model is as follows:\n",
    "\n",
    "\n",
    "- **Results**: \n",
    "\n",
    "Below is the table showing the the accuracy as the number of categories representing the discretized percentage returns changes\n",
    "\n",
    "|  num_cat |  2  |  5  |  10  |  14  |\n",
    "|----------|-----|-----|------|------|\n",
    "| accuracy | --  | --  |  --  | 0.18 |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the required packages\n",
    "import plotly.graph_objects as go\n",
    "import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Scrape_Historical_Data import scrape_historical_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_stocks = [\n",
    "\"MSFT\", \"AAPL\", \"AMZN\", \"GOOG\", \"GOOGL\", \"FB\", \"BRK.B\", \"V\", \"WMT\", \"JPM\", \"PG\", \n",
    "\"MA\", \"UNH\", \"INTC\", \"VZ\", \"T\", \"HD\", \"BAC\", \"MRK\", \"DIS\", \"PFE\", \"PEP\", \"CSCO\", \n",
    "\"CMCSA\", \"ORCL\", \"NFLX\", \"XOM\", \"NVDA\", \"ADBE\", \"ABT\", \"CRM\", \"NKE\", \"CVX\", \"LLY\", \"COST\", \n",
    "\"WFC\", \"MCD\", \"MDT\", \"BMY\", \"AMGN\", \"NEE\", \"PYPL\", \"TMO\", \"PM\", \"ABBV\", \"ACN\", \"CHTR\", \n",
    "\"LMT\", \"DHR\", \"UNP\", \"IBM\", \"TXN\", \"HON\", \"AVGO\", \"GILD\", \"C\", \"BA\", \"LIN\", \"UTX\", \n",
    "\"UPS\", \"SBUX\", \"MMM\", \"CVS\", \"QCOM\", \"FIS\", \"AXP\", \"TMUS\", \"MDLZ\", \"MO\", \"BLK\", \"LOW\", \"GE\", \n",
    "\"FISV\", \"CME\", \"D\", \"CI\", \"INTU\", \"SYK\", \"SO\", \"BDX\", \"PLD\", \"CAT\", \"EL\", \"SPGI\", \n",
    "\"ISRG\", \"CCI\", \"AGN\", \"TJX\", \"ADP\", \"VRTX\", \"ANTM\", \"CL\", \"GS\", \"AMD\", \"USB\", \"ZTS\", \"NOC\", \n",
    "\"MS\", \"NOW\", \"BIIB\", \"BKNG\", \"EQIX\", \"REGN\", \"CB\", \"MU\", \"TGT\", \"ITW\", \"ECL\", \"TFC\", \n",
    "\"ATVI\", \"CSX\", \"GPN\", \"SCHW\", \"MMC\", \"PGR\", \"PNC\", \"BSX\", \"KMB\", \"APD\", \"DE\", \"SHW\", \"AMAT\", \n",
    "\"AEP\", \"MCO\", \"EW\", \"WM\", \"BAX\", \"LHX\", \"NSC\", \"ILMN\", \"RTN\", \"HUM\", \"WBA\", \"SPG\",  \n",
    "\"GD\", \"NEM\", \"DG\", \"SRE\", \"LRCX\", \"EXC\", \"DLR\", \"PSA\", \"ADI\", \"ROP\", \"CNC\", \"LVS\", \"COP\", \n",
    "\"FDX\", \"GIS\", \"KMI\", \"ADSK\", \"XEL\", \"ETN\", \"GM\", \"MNST\", \"ROST\", \"KHC\", \"HCA\", \"SBAC\", \"BK\", \n",
    "\"MET\", \"WEC\", \"ALL\", \"EMR\", \"STZ\", \"EA\", \"HSY\", \"ES\", \"ED\", \"SYY\", \"CTSH\", \"AFL\", \n",
    "\"MAR\", \"TRV\", \"COF\", \"DD\", \"HRL\", \"HPQ\", \"RSG\", \"EBAY\", \"INFO\", \"MSCI\", \"EQR\", \"ORLY\", \"MSI\", \n",
    "\"TROW\", \"KR\", \"PSX\", \"VFC\", \"AVB\", \"PEG\", \"VRSK\", \"KLAC\", \"AIG\", \"MCK\", \"APH\", \"A\", \"AWK\", \n",
    "\"CLX\", \"PAYX\", \"WLTW\", \"DOW\", \"PRU\", \"TEL\", \"BLL\", \"EOG\", \"FE\", \"IQV\", \"YUM\", \"PCAR\", \"F\", \n",
    "\"RMD\", \"WELL\", \"K\", \"VRSN\", \"EIX\", \"PPG\", \"AZO\", \"JCI\", \"TWTR\", \"CMI\", \"IDXX\", \"TT\", \"ZBH\", \n",
    "\"O\", \"PPL\", \"ETR\", \"HLT\", \"ANSS\", \"SLB\", \"DAL\", \"CTAS\", \"LUV\", \"DTE\", \"XLNX\", \"SNPS\", \n",
    "\"ADM\", \"ALXN\", \"VLO\", \"AEE\", \"CERN\", \"DLTR\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Historical price data for MSFT is scraped.\n",
      "Historical price data for AAPL is scraped.\n",
      "Historical price data for AMZN is scraped.\n",
      "Historical price data for GOOG is scraped.\n",
      "Historical price data for GOOGL is scraped.\n",
      "Historical price data for FB is scraped.\n",
      "Historical price data for BRK.B is scraped.\n",
      "Historical price data for V is scraped.\n",
      "Historical price data for WMT is scraped.\n",
      "Historical price data for JPM is scraped.\n",
      "Historical price data for PG is scraped.\n",
      "Historical price data for MA is scraped.\n",
      "Historical price data for UNH is scraped.\n",
      "Historical price data for INTC is scraped.\n",
      "Historical price data for VZ is scraped.\n",
      "Historical price data for T is scraped.\n",
      "Historical price data for HD is scraped.\n",
      "Historical price data for BAC is scraped.\n",
      "Historical price data for MRK is scraped.\n",
      "Historical price data for DIS is scraped.\n",
      "Historical price data for PFE is scraped.\n",
      "Historical price data for PEP is scraped.\n",
      "Historical price data for CSCO is scraped.\n",
      "Historical price data for CMCSA is scraped.\n",
      "Historical price data for ORCL is scraped.\n",
      "Historical price data for NFLX is scraped.\n",
      "Historical price data for XOM is scraped.\n",
      "Historical price data for NVDA is scraped.\n",
      "Historical price data for ADBE is scraped.\n",
      "Historical price data for ABT is scraped.\n",
      "Historical price data for CRM is scraped.\n",
      "Historical price data for NKE is scraped.\n",
      "Historical price data for CVX is scraped.\n",
      "Historical price data for LLY is scraped.\n",
      "Historical price data for COST is scraped.\n",
      "Historical price data for WFC is scraped.\n",
      "Historical price data for MCD is scraped.\n",
      "Historical price data for MDT is scraped.\n",
      "Historical price data for BMY is scraped.\n",
      "Historical price data for AMGN is scraped.\n",
      "Historical price data for NEE is scraped.\n",
      "Historical price data for PYPL is scraped.\n",
      "Historical price data for TMO is scraped.\n",
      "Historical price data for PM is scraped.\n",
      "Historical price data for ABBV is scraped.\n",
      "Historical price data for ACN is scraped.\n",
      "Historical price data for CHTR is scraped.\n",
      "Historical price data for LMT is scraped.\n",
      "Historical price data for DHR is scraped.\n",
      "Historical price data for UNP is scraped.\n",
      "Historical price data for IBM is scraped.\n",
      "Historical price data for TXN is scraped.\n",
      "Historical price data for HON is scraped.\n",
      "Historical price data for AVGO is scraped.\n",
      "Historical price data for GILD is scraped.\n",
      "Historical price data for C is scraped.\n",
      "Historical price data for BA is scraped.\n",
      "Historical price data for LIN is scraped.\n",
      "Historical price data for UTX is scraped.\n",
      "Historical price data for UPS is scraped.\n",
      "Historical price data for SBUX is scraped.\n",
      "Historical price data for MMM is scraped.\n",
      "Historical price data for CVS is scraped.\n",
      "Historical price data for QCOM is scraped.\n",
      "Historical price data for FIS is scraped.\n",
      "Historical price data for AXP is scraped.\n",
      "Historical price data for TMUS is scraped.\n",
      "Historical price data for MDLZ is scraped.\n",
      "Historical price data for MO is scraped.\n",
      "Historical price data for BLK is scraped.\n",
      "Historical price data for LOW is scraped.\n",
      "Historical price data for GE is scraped.\n",
      "Historical price data for FISV is scraped.\n",
      "Historical price data for CME is scraped.\n",
      "Historical price data for D is scraped.\n",
      "Historical price data for CI is scraped.\n",
      "Historical price data for INTU is scraped.\n",
      "Historical price data for SYK is scraped.\n",
      "Historical price data for SO is scraped.\n",
      "Historical price data for BDX is scraped.\n",
      "Historical price data for PLD is scraped.\n",
      "Historical price data for CAT is scraped.\n",
      "Historical price data for EL is scraped.\n",
      "Historical price data for SPGI is scraped.\n",
      "Historical price data for ISRG is scraped.\n",
      "Historical price data for CCI is scraped.\n",
      "Historical price data for AGN is scraped.\n",
      "Historical price data for TJX is scraped.\n",
      "Historical price data for ADP is scraped.\n",
      "Historical price data for VRTX is scraped.\n",
      "Historical price data for ANTM is scraped.\n",
      "Historical price data for CL is scraped.\n",
      "Historical price data for GS is scraped.\n",
      "Historical price data for AMD is scraped.\n",
      "Historical price data for USB is scraped.\n",
      "Historical price data for ZTS is scraped.\n",
      "Historical price data for NOC is scraped.\n",
      "Historical price data for MS is scraped.\n",
      "Historical price data for NOW is scraped.\n",
      "Historical price data for BIIB is scraped.\n",
      "Historical price data for BKNG is scraped.\n",
      "Historical price data for EQIX is scraped.\n",
      "Historical price data for REGN is scraped.\n",
      "Historical price data for CB is scraped.\n",
      "Historical price data for MU is scraped.\n",
      "Historical price data for TGT is scraped.\n",
      "Historical price data for ITW is scraped.\n",
      "Historical price data for ECL is scraped.\n",
      "Historical price data for TFC is scraped.\n",
      "Historical price data for ATVI is scraped.\n",
      "Historical price data for CSX is scraped.\n",
      "Historical price data for GPN is scraped.\n",
      "Historical price data for SCHW is scraped.\n",
      "Historical price data for MMC is scraped.\n",
      "Historical price data for PGR is scraped.\n",
      "Historical price data for PNC is scraped.\n",
      "Historical price data for BSX is scraped.\n",
      "Historical price data for KMB is scraped.\n",
      "Historical price data for APD is scraped.\n",
      "Historical price data for DE is scraped.\n",
      "Historical price data for SHW is scraped.\n",
      "Historical price data for AMAT is scraped.\n",
      "Historical price data for AEP is scraped.\n",
      "Historical price data for MCO is scraped.\n",
      "Historical price data for EW is scraped.\n",
      "Historical price data for WM is scraped.\n",
      "Historical price data for BAX is scraped.\n",
      "Historical price data for LHX is scraped.\n",
      "Historical price data for NSC is scraped.\n",
      "Historical price data for ILMN is scraped.\n",
      "Historical price data for RTN is scraped.\n",
      "Historical price data for HUM is scraped.\n",
      "Historical price data for WBA is scraped.\n",
      "Historical price data for SPG is scraped.\n",
      "Historical price data for GD is scraped.\n",
      "Historical price data for NEM is scraped.\n",
      "Historical price data for DG is scraped.\n",
      "Historical price data for SRE is scraped.\n",
      "Historical price data for LRCX is scraped.\n",
      "Historical price data for EXC is scraped.\n",
      "Historical price data for DLR is scraped.\n",
      "Historical price data for PSA is scraped.\n",
      "Historical price data for ADI is scraped.\n",
      "Historical price data for ROP is scraped.\n",
      "Historical price data for CNC is scraped.\n",
      "Historical price data for LVS is scraped.\n",
      "Historical price data for COP is scraped.\n",
      "Historical price data for FDX is scraped.\n",
      "Historical price data for GIS is scraped.\n",
      "Historical price data for KMI is scraped.\n",
      "Historical price data for ADSK is scraped.\n",
      "Historical price data for XEL is scraped.\n",
      "Historical price data for ETN is scraped.\n",
      "Historical price data for GM is scraped.\n",
      "Historical price data for MNST is scraped.\n",
      "Historical price data for ROST is scraped.\n",
      "Historical price data for KHC is scraped.\n",
      "Historical price data for HCA is scraped.\n",
      "Historical price data for SBAC is scraped.\n",
      "Historical price data for BK is scraped.\n",
      "Historical price data for MET is scraped.\n",
      "Historical price data for WEC is scraped.\n",
      "Historical price data for ALL is scraped.\n",
      "Historical price data for EMR is scraped.\n",
      "Historical price data for STZ is scraped.\n",
      "Historical price data for EA is scraped.\n",
      "Historical price data for HSY is scraped.\n",
      "Historical price data for ES is scraped.\n",
      "Historical price data for ED is scraped.\n",
      "Historical price data for SYY is scraped.\n",
      "Historical price data for CTSH is scraped.\n",
      "Historical price data for AFL is scraped.\n",
      "Historical price data for MAR is scraped.\n",
      "Historical price data for TRV is scraped.\n",
      "Historical price data for COF is scraped.\n",
      "Historical price data for DD is scraped.\n",
      "Historical price data for HRL is scraped.\n",
      "Historical price data for HPQ is scraped.\n",
      "Historical price data for RSG is scraped.\n",
      "Historical price data for EBAY is scraped.\n",
      "Historical price data for INFO is scraped.\n",
      "Historical price data for MSCI is scraped.\n",
      "Historical price data for EQR is scraped.\n",
      "Historical price data for ORLY is scraped.\n",
      "Historical price data for MSI is scraped.\n",
      "Historical price data for TROW is scraped.\n",
      "Historical price data for KR is scraped.\n",
      "Historical price data for PSX is scraped.\n",
      "Historical price data for VFC is scraped.\n",
      "Historical price data for AVB is scraped.\n",
      "Historical price data for PEG is scraped.\n",
      "Historical price data for VRSK is scraped.\n",
      "Historical price data for KLAC is scraped.\n",
      "Historical price data for AIG is scraped.\n",
      "Historical price data for MCK is scraped.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Historical price data for APH is scraped.\n",
      "Historical price data for A is scraped.\n",
      "Historical price data for AWK is scraped.\n",
      "Historical price data for CLX is scraped.\n",
      "Historical price data for PAYX is scraped.\n",
      "Historical price data for WLTW is scraped.\n",
      "Historical price data for DOW is scraped.\n",
      "Historical price data for PRU is scraped.\n",
      "Historical price data for TEL is scraped.\n",
      "Historical price data for BLL is scraped.\n",
      "Historical price data for EOG is scraped.\n",
      "Historical price data for FE is scraped.\n",
      "Historical price data for IQV is scraped.\n",
      "Historical price data for YUM is scraped.\n",
      "Historical price data for PCAR is scraped.\n",
      "Historical price data for F is scraped.\n",
      "Historical price data for RMD is scraped.\n",
      "Historical price data for WELL is scraped.\n",
      "Historical price data for K is scraped.\n",
      "Historical price data for VRSN is scraped.\n",
      "Historical price data for EIX is scraped.\n",
      "Historical price data for PPG is scraped.\n",
      "Historical price data for AZO is scraped.\n",
      "Historical price data for JCI is scraped.\n",
      "Historical price data for TWTR is scraped.\n",
      "Historical price data for CMI is scraped.\n",
      "Historical price data for IDXX is scraped.\n",
      "Historical price data for TT is scraped.\n",
      "Historical price data for ZBH is scraped.\n",
      "Historical price data for O is scraped.\n",
      "Historical price data for PPL is scraped.\n",
      "Historical price data for ETR is scraped.\n",
      "Historical price data for HLT is scraped.\n",
      "Historical price data for ANSS is scraped.\n",
      "Historical price data for SLB is scraped.\n",
      "Historical price data for DAL is scraped.\n",
      "Historical price data for CTAS is scraped.\n",
      "Historical price data for LUV is scraped.\n",
      "Historical price data for DTE is scraped.\n",
      "Historical price data for XLNX is scraped.\n",
      "Historical price data for SNPS is scraped.\n",
      "Historical price data for ADM is scraped.\n",
      "Historical price data for ALXN is scraped.\n",
      "Historical price data for VLO is scraped.\n",
      "Historical price data for AEE is scraped.\n",
      "Historical price data for CERN is scraped.\n",
      "Historical price data for DLTR is scraped.\n",
      "\n",
      "Data scraping is complete.\n"
     ]
    }
   ],
   "source": [
    "for stock_code in list_stocks: \n",
    "    scrape_historical_data(stock_code)\n",
    "print('\\nData scraping is complete.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Data and Creating Image Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import functions I created \n",
    "from DataFrame_Preprocessors import cleaner, calculate_return, categorizer \n",
    "from Bollinger_Bands import bollinger_bands \n",
    "from Image_Creator import image_creator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_interval = 22\n",
    "categories = (-1, 0, 1)\n",
    "\n",
    "for sub_dir in categories:\n",
    "    images_dir = 'images/{}'.format(sub_dir)\n",
    "    if not os.path.exists(images_dir):\n",
    "        os.makedirs(images_dir)\n",
    "\n",
    "for stock_name in os.listdir('historical_price_data'):    \n",
    "    data_path = 'historical_price_data/' + stock_name \n",
    "    \n",
    "    if os.stat(data_path).st_size <= 5:\n",
    "        continue  \n",
    "\n",
    "    stock_price = pd.read_csv(data_path)\n",
    "\n",
    "    if len(stock_price) < 200 :\n",
    "        continue \n",
    "\n",
    "    stock_price = cleaner(stock_price)\n",
    "    stock_price = bollinger_bands(stock_price)\n",
    "    stock_price = calculate_return(stock_price)\n",
    "    stock_price = categorizer(stock_price)\n",
    "\n",
    "    for start in range(len(stock_price) - time_interval):\n",
    "        end = start + time_interval\n",
    "        sub_stock_price = stock_price[start: end] \n",
    "        file_name = '{}_{}'.format(stock_name[:-4], start)\n",
    "        \n",
    "        image_creator(df = sub_stock_price, file_name = file_name)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Train_Test_Directory_Split import train_test_directory_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=====================================\n",
      "Total images in class -1 is 164605\n",
      "\t98763 copied to ../training/-1\n",
      "\t32921 copied to ../validation/-1\n",
      "\t32921 copied to ../testing/-1\n",
      "\n",
      "=====================================\n",
      "Total images in class 0 is 189794\n",
      "\t113876 copied to ../training/0\n",
      "\t37959 copied to ../validation/0\n",
      "\t37959 copied to ../testing/0\n",
      "\n",
      "=====================================\n",
      "Total images in class 1 is 189666\n",
      "\t113799 copied to ../training/1\n",
      "\t37933 copied to ../validation/1\n",
      "\t37934 copied to ../testing/1\n"
     ]
    }
   ],
   "source": [
    "# Prepare the data directory to flow_from_direcoty method \n",
    "train_test_directory_split(classes=categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 64, 64, 88)        2288      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 88)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 16, 16, 44)        96844     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 44)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 704)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 2115      \n",
      "=================================================================\n",
      "Total params: 101,247\n",
      "Trainable params: 101,247\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Found 326438 images belonging to 3 classes.\n",
      "Found 108813 images belonging to 3 classes.\n",
      "Epoch 1/6\n",
      "20403/20403 [==============================] - 1045s 51ms/step - loss: 1.0966 - accuracy: 0.3476 - val_loss: 1.0970 - val_accuracy: 0.3488\n",
      "Epoch 2/6\n",
      "20403/20403 [==============================] - 953s 47ms/step - loss: 1.0965 - accuracy: 0.3476 - val_loss: 1.0975 - val_accuracy: 0.3486\n",
      "Epoch 3/6\n",
      "20403/20403 [==============================] - 971s 48ms/step - loss: 1.0965 - accuracy: 0.3484 - val_loss: 1.0898 - val_accuracy: 0.3488\n",
      "Epoch 4/6\n",
      "20403/20403 [==============================] - 685s 34ms/step - loss: 1.0965 - accuracy: 0.3493 - val_loss: 1.0788 - val_accuracy: 0.3486\n",
      "Epoch 5/6\n",
      "20403/20403 [==============================] - 829s 41ms/step - loss: 1.0965 - accuracy: 0.3500 - val_loss: 1.0808 - val_accuracy: 0.3488\n",
      "Epoch 6/6\n",
      "20403/20403 [==============================] - 655s 32ms/step - loss: 1.0965 - accuracy: 0.3480 - val_loss: 1.0769 - val_accuracy: 0.3488\n",
      "Found 108814 images belonging to 3 classes.\n",
      "[1.0843021869659424, 0.348842978477478]\n"
     ]
    }
   ],
   "source": [
    "import CNN_Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results \n",
    "\n",
    "Here we have tried to classify the 22 day candlestick chart of a stock with its bollinger bands into three categories, namely as follows: \n",
    "    \n",
    "    - category  1: percentage return > 0.5% \n",
    "    - category  0: percentage return between -0.5% and +0.5% \n",
    "    - category -1: percentage return < -0.5% \n",
    "\n",
    "The resulting accuracy is . In next version, I will try to improve the architecture of the network and present the precision and recall as well. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> <center> Predicting Day Trade Return by Deep Learning </center> </h1>\n",
    "\n",
    "The aim of this project: Predicting the possible outcome of a day trade by training a deep learning model on the image data of historic candle stick charts with some financial indicators drawn on them \n",
    "\n",
    "- **Data Scraping**: \n",
    "\n",
    "\tFor 100 stocks listed in S&P500 index, scraped the historical price data for the last five years. \n",
    "\n",
    "\n",
    "- **Creating .png images***:\n",
    "\n",
    "\tFor ever 22 day long interval, draw the candlestick chart of the data along with some financial indicators (bollinger bands for now) on it\n",
    "\tFor each image file, created day_trade_precentage feature - calculated as the percentage return of buying the stock at the Close price of the 22nd day (the last day included in the candle stick chart) and selling it at the next day's Close price\n",
    "\tDiscretized the percentage return into N many categories. \n",
    "\t\tHow are the categories created? \n",
    "\tSave the image files in the directory images/label, where label is its category\n",
    "\n",
    "\n",
    "- **Preparing Data Directory for flow_from_directory**: \n",
    "\n",
    "\tIn order to be able to use flow_from_directory method of Keras, split the data into 3 directories under images_separated directory, called train_data, validation_data, test_data. The structure of the directory is as follows:\n",
    "\n",
    "\t```pyton \n",
    "    images_separated/\n",
    "\t\ttrain_data/\n",
    "\t\t\tlabel_1/\n",
    "\t\t\t\ttrain1_image_1.png\n",
    "\t\t\t\ttrain1_image_2.png\n",
    "\t\t\t\t...\n",
    "\t\t\tlabel_2/\n",
    "\t\t\t\ttrain2_image_1.png\n",
    "\t\t\t\ttrain2_image_2.png\n",
    "\t\t\t\t...\n",
    "\t\t\t...\n",
    "\t\tvalidation_data/\n",
    "\t\t\tlabel_1/\n",
    "\t\t\t\tvalidation1_image_1.png\n",
    "\t\t\t\tvalidation1_image_2.png\n",
    "\t\t\t\t...\n",
    "\t\t\tlabel_2/\n",
    "\t\t\t\tvalidation2_image_1.png\n",
    "\t\t\t\tvalidation2_image_2.png\n",
    "\t\t\t\t...\n",
    "\t\t\t...\n",
    "\t\ttest_data/\n",
    "\t\t\tlabel_1/\n",
    "\t\t\t\ttest1_image_1.png\n",
    "\t\t\t\ttest1_image_2.png\n",
    "\t\t\t\t...\n",
    "\t\t\tlabel_2/\n",
    "\t\t\t\ttest2_image_1.png\n",
    "\t\t\t\ttest2_image_2.png\n",
    "\t\t\t\t...\n",
    "\t\t\t...\n",
    "    ```\n",
    "\n",
    "- **Train CNN model**: \n",
    "\n",
    "\tThe architecture of the CNN model is as follows:\n",
    "\n",
    "\n",
    "- **Results**: \n",
    "\n",
    "Below is the table showing the the accuracy as the number of categories representing the discretized percentage returns changes\n",
    "\n",
    "|  num_cat |  2  |  5  |  10  |  14  |\n",
    "|----------|-----|-----|------|------|\n",
    "| accuracy | --  | --  |  --  | 0.18 |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the required packages\n",
    "import plotly.graph_objects as go\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math \n",
    "\n",
    "# Import functions I created \n",
    "from Bollinger_Bands import bollinger_bands\n",
    "from DataFrame_Preprocessors import cleaner, calculate_return, categorizer \n",
    "from Image_Creator import image_creator\n",
    "from Train_Test_Directory_Split import train_test_directory_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To be filled "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Image Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_interval = 22\n",
    "# create a pd dataframe to store the labels for each feature\n",
    "df_labels = pd.DataFrame(columns = ['feature', 'label'])\n",
    "\n",
    "if not os.path.exists('images'): \n",
    "    os.mkdir('images')\n",
    "\n",
    "for stock_name in os.listdir('data_folder'):    \n",
    "    data_path = 'data_folder/' + stock_name \n",
    "\n",
    "    if os.stat(data_path).st_size <= 5:\n",
    "        pass \n",
    "\n",
    "    stock_price = pd.read_csv(data_path)\n",
    "\n",
    "    if len(stock_price) < 60 :\n",
    "        pass\n",
    "\n",
    "    stock_price = cleaner(stock_price)\n",
    "    stock_price = bollinger_bands(stock_price)\n",
    "    stock_price = calculate_return(stock_price)\n",
    "    stock_price = categorizer(stock_price)\n",
    "\n",
    "    for start in range(len(stock_price) - time_interval):\n",
    "        end = start + time_interval\n",
    "        sub_stock_price = stock_price[start: end] \n",
    "        file_name = '{}_{}'.format(stock_name[:-4], start)\n",
    "        \n",
    "        image_creator(df = sub_stock_price, file_name = file_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data directory to flow_from_direcoty method \n",
    "train_test_directory_split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cnn_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 64, 64, 44)        1144      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 44)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 16, 16, 44)        48444     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 44)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4, 4, 44)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 704)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 14)                9870      \n",
      "=================================================================\n",
      "Total params: 59,458\n",
      "Trainable params: 59,458\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Found 72433 images belonging to 14 classes.\n",
      "Found 24145 images belonging to 14 classes.\n",
      "Epoch 1/10\n",
      "5000/5000 [==============================] - 194s 39ms/step - loss: 2.3230 - accuracy: 0.1875 - val_loss: 2.3291 - val_accuracy: 0.1873\n",
      "Epoch 2/10\n",
      "5000/5000 [==============================] - 174s 35ms/step - loss: 2.3207 - accuracy: 0.1904 - val_loss: 2.4767 - val_accuracy: 0.1910\n",
      "Epoch 3/10\n",
      "5000/5000 [==============================] - 119s 24ms/step - loss: 2.3156 - accuracy: 0.1878 - val_loss: 2.2846 - val_accuracy: 0.1874\n",
      "Epoch 4/10\n",
      "5000/5000 [==============================] - 112s 22ms/step - loss: 2.3167 - accuracy: 0.1889 - val_loss: 2.6157 - val_accuracy: 0.1857\n",
      "Epoch 5/10\n",
      "5000/5000 [==============================] - 111s 22ms/step - loss: 2.3173 - accuracy: 0.1876 - val_loss: 2.2596 - val_accuracy: 0.1865\n",
      "Epoch 6/10\n",
      "5000/5000 [==============================] - 115s 23ms/step - loss: 2.3160 - accuracy: 0.1863 - val_loss: 2.1266 - val_accuracy: 0.1886\n",
      "Epoch 7/10\n",
      "5000/5000 [==============================] - 113s 23ms/step - loss: 2.3184 - accuracy: 0.1878 - val_loss: 2.1534 - val_accuracy: 0.1898\n",
      "Epoch 8/10\n",
      "5000/5000 [==============================] - 111s 22ms/step - loss: 2.3165 - accuracy: 0.1877 - val_loss: 2.5306 - val_accuracy: 0.1855\n",
      "Epoch 9/10\n",
      "5000/5000 [==============================] - 111s 22ms/step - loss: 2.3153 - accuracy: 0.1888 - val_loss: 2.1672 - val_accuracy: 0.1879\n",
      "Epoch 10/10\n",
      "5000/5000 [==============================] - 112s 22ms/step - loss: 2.3172 - accuracy: 0.1854 - val_loss: 2.3094 - val_accuracy: 0.1890\n",
      "Found 24151 images belonging to 14 classes.\n"
     ]
    }
   ],
   "source": [
    "import CNN_Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
